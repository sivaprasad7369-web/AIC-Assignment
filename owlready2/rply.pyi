"""
This type stub file was generated by pyright.
"""

class ParserGeneratorError(Exception):
  ...


class LexingError(Exception):
  def __init__(self, message, source_pos) -> None:
    ...
  


class ParsingError(Exception):
  def __init__(self, message, source_pos) -> None:
    ...
  


class IdentityDict:
  def __init__(self) -> None:
    ...
  
  def get(self, key, default=...): # -> None:
    ...
  
  def __getitem__(self, key):
    ...
  
  def __setitem__(self, key, value): # -> None:
    ...
  
  def __delitem__(self, key): # -> None:
    ...
  
  def __len__(self): # -> int:
    ...
  
  def __iter__(self): # -> Generator[Any, Any, None]:
    ...
  


class Counter:
  def __init__(self) -> None:
    ...
  
  def incr(self): # -> None:
    ...
  


class Token:
  alias = ...
  def __init__(self, name, value, source_pos=...) -> None:
    ...
  
  def __repr__(self): # -> Any | str:
    ...
  
  def __eq__(self, other) -> bool:
    ...
  
  def __hash__(self) -> int:
    ...
  


def rightmost_terminal(symbols, terminals): # -> None:
  ...

class Grammar:
  def __init__(self, terminals) -> None:
    ...
  
  def add_production(self, prod_name, syms, func, precedence): # -> None:
    ...
  
  def set_precedence(self, term, assoc, level): # -> None:
    ...
  
  def set_start(self): # -> None:
    ...
  
  def unused_terminals(self): # -> list[Any]:
    ...
  
  def unused_productions(self): # -> list[Any]:
    ...
  
  def build_lritems(self): # -> None:
    ...
  
  def compute_first(self): # -> None:
    ...
  
  def compute_follow(self): # -> None:
    ...
  


class Production:
  def __init__(self, num, name, prod, precedence, func) -> None:
    ...
  
  def __repr__(self): # -> LiteralString:
    ...
  
  def getlength(self): # -> int:
    ...
  


class LRItem:
  def __init__(self, p, n, before, after) -> None:
    ...
  
  def __repr__(self): # -> str:
    ...
  
  def getlength(self): # -> int:
    ...
  


class Lexer:
  def __init__(self, rules, ignore_rules) -> None:
    ...
  
  def lex(self, s): # -> LexerStream:
    ...
  


class LexerStream:
  def __init__(self, lexer, s) -> None:
    ...
  
  def __iter__(self): # -> Self:
    ...
  
  def next(self): # -> Token:
    ...
  
  __next__ = ...


exec_regexp = ...
class Rule:
  def __init__(self, name, pattern, flags=...) -> None:
    ...
  
  def matches(self, s, pos): # -> tuple[Any, Any] | None:
    ...
  


class LexerGenerator:
  def __init__(self) -> None:
    ...
  
  def add(self, name, pattern, flags=...): # -> None:
    ...
  
  def ignore(self, pattern, flags=...): # -> None:
    ...
  
  def build(self): # -> Lexer:
    ...
  


class LRParser:
  def __init__(self, lr_table, error_handler) -> None:
    ...
  
  def parse(self, tokenizer, state=...): # -> Token:
    ...
  


LARGE_VALUE = ...
class ParserGenerator:
  def __init__(self, tokens, precedence=..., cache_id=...) -> None:
    ...
  
  def production(self, rule, precedence=...): # -> Callable[..., Any]:
    ...
  
  def optional(self, name, args=...): # -> None:
    ...
  
  def list(self, name, sep=..., keep_sep=...): # -> None:
    ...
  
  def error(self, func):
    ...
  
  def data_is_valid(self, g, data): # -> bool:
    ...
  
  def build(self): # -> LRParser:
    ...
  


def digraph(X, R, FP): # -> dict[Any, Any]:
  ...

def traverse(x, N, stack, F, X, R, FP): # -> None:
  ...

class LRTable:
  def __init__(self, grammar, lr_action, lr_goto, default_reductions, sr_conflicts, rr_conflicts) -> None:
    ...
  
  @classmethod
  def from_cache(cls, grammar, data): # -> LRTable:
    ...
  
  @classmethod
  def from_grammar(cls, grammar):
    ...
  
  @classmethod
  def lr0_items(cls, grammar, add_count, cidhash, goto_cache): # -> list[Any]:
    ...
  
  @classmethod
  def lr0_closure(cls, I, add_count):
    ...
  
  @classmethod
  def lr0_goto(cls, I, x, add_count, goto_cache): # -> None:
    ...
  
  @classmethod
  def add_lalr_lookaheads(cls, grammar, C, add_count, cidhash, goto_cache): # -> None:
    ...
  
  @classmethod
  def compute_nullable_nonterminals(cls, grammar): # -> set[Any]:
    ...
  
  @classmethod
  def find_nonterminal_transitions(cls, grammar, C): # -> list[Any]:
    ...
  
  @classmethod
  def compute_read_sets(cls, grammar, C, ntrans, nullable, add_count, cidhash, goto_cache): # -> dict[Any, Any]:
    ...
  
  @classmethod
  def compute_follow_sets(cls, ntrans, readsets, includesets): # -> dict[Any, Any]:
    ...
  
  @classmethod
  def dr_relation(cls, grammar, C, trans, nullable, add_count, goto_cache): # -> list[Any]:
    ...
  
  @classmethod
  def reads_relation(cls, C, trans, empty, add_count, cidhash, goto_cache): # -> list[Any]:
    ...
  
  @classmethod
  def compute_lookback_includes(cls, grammar, C, trans, nullable, add_count, cidhash, goto_cache): # -> tuple[dict[Any, Any], dict[Any, Any]]:
    ...
  
  @classmethod
  def add_lookaheads(cls, lookbacks, followset): # -> None:
    ...
  


